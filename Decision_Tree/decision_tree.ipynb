{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: The compiler package is deprecated and removed in Python 3.x.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import division\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from math import log\n",
    "from compiler.ast import flatten\n",
    "\n",
    "\n",
    "# This method computes entropy for information gain\n",
    "def entropy(class_y):\n",
    "    # Input:            \n",
    "    # class_y         : list of class labels (0's and 1's)\n",
    "\n",
    "    # TODO: Compute the entropy for a list of classes\n",
    "    #\n",
    "    # Example:\n",
    "    #    entropy([0,0,0,1,1,1,1,1,1]) = 0.92\n",
    "    log2 = lambda x: log(x) / log(2)\n",
    "    labels = np.unique(class_y)\n",
    "    entropy = 0\n",
    "\n",
    "    y = np.asarray(class_y)\n",
    "    for label in labels:\n",
    "        count = len(y[y == label])\n",
    "        p = count / len(class_y)\n",
    "        entropy += -p * log2(p)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "\n",
    "def try_partition_classes(X, y, split_attribute, split_val):\n",
    "    y_left = []\n",
    "    y_right = []\n",
    "\n",
    "    X_arr = np.asarray(X, dtype=object)\n",
    "    y_arr = np.array(y)\n",
    "\n",
    "    # If split_attribute is numeric, then split on <= condition\n",
    "    if not type(split_val)==str:\n",
    "        idx_left = np.where(X_arr[:,split_attribute] <= split_val)[0]\n",
    "        idx_right = np.where(X_arr[:,split_attribute] > split_val)[0]\n",
    "        y_left = y_arr[idx_left].tolist()\n",
    "        y_right = y_arr[idx_right].tolist()\n",
    "\n",
    "    # If split_attribute is categorical, then split on split_val\n",
    "    else:\n",
    "        idx_left = np.where(X_arr[:,split_attribute] == split_val)[0]\n",
    "        idx_right = np.where(X_arr[:,split_attribute] != split_val)[0]    \n",
    "        y_left = y_arr[idx_left].tolist()\n",
    "        y_right = y_arr[idx_right].tolist()\n",
    "\n",
    "    return (y_left, y_right)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def partition_classes(X, y, split_attribute, split_val):\n",
    "    # Inputs:\n",
    "    #   X               : data containing all attributes\n",
    "    #   y               : labels\n",
    "    #   split_attribute : column index of the attribute to split on\n",
    "    #   split_val       : either a numerical or categorical value to divide the split_attribute\n",
    "    \n",
    "    # TODO: Partition the data(X) and labels(y) based on the split value - BINARY SPLIT.\n",
    "    # \n",
    "    # You will have to first check if the split attribute is numerical or categorical    \n",
    "    # If the split attribute is numeric, split_val should be a numerical value\n",
    "    # For example, your split_val could be the mean of the values of split_attribute\n",
    "    # If the split attribute is categorical, split_val should be one of the categories.   \n",
    "    #\n",
    "    # You can perform the partition in the following way\n",
    "    # Numeric Split Attribute:\n",
    "    #   Split the data X into two lists(X_left and X_right) where the first list has all\n",
    "    #   the rows where the split attribute is less than or equal to the split value, and the \n",
    "    #   second list has all the rows where the split attribute is greater than the split \n",
    "    #   value. Also create two lists(y_left and y_right) with the corresponding y labels.\n",
    "    #\n",
    "    # Categorical Split Attribute:\n",
    "    #   Split the data X into two lists(X_left and X_right) where the first list has all \n",
    "    #   the rows where the split attribute is equal to the split value, and the second list\n",
    "    #   has all the rows where the split attribute is not equal to the split value.\n",
    "    #   Also create two lists(y_left and y_right) with the corresponding y labels.\n",
    "\n",
    "    '''\n",
    "    Example:\n",
    "    \n",
    "    X = [[3, 'aa', 10],                 y = [1,\n",
    "         [1, 'bb', 22],                      1,\n",
    "         [2, 'cc', 28],                      0,\n",
    "         [5, 'bb', 32],                      0,\n",
    "         [4, 'cc', 32]]                      1]\n",
    "    \n",
    "    Here, columns 0 and 2 represent numeric attributes, while column 1 is a categorical attribute.\n",
    "    \n",
    "    Consider the case where we call the function with split_attribute = 0 and split_val = 3 (mean of column 0)\n",
    "    Then we divide X into two lists - X_left, where column 0 is <= 3  and X_right, where column 0 is > 3.\n",
    "    \n",
    "    X_left = [[3, 'aa', 10],                 y_left = [1,\n",
    "              [1, 'bb', 22],                           1,\n",
    "              [2, 'cc', 28]]                           0]\n",
    "              \n",
    "    X_right = [[5, 'bb', 32],                y_right = [0,\n",
    "               [4, 'cc', 32]]                           1]\n",
    "\n",
    "    Consider another case where we call the function with split_attribute = 1 and split_val = 'bb'\n",
    "    Then we divide X into two lists, one where column 1 is 'bb', and the other where it is not 'bb'.\n",
    "        \n",
    "    X_left = [[1, 'bb', 22],                 y_left = [1,\n",
    "              [5, 'bb', 32]]                           0]\n",
    "              \n",
    "    X_right = [[3, 'aa', 10],                y_right = [1,\n",
    "               [2, 'cc', 28],                           0,\n",
    "               [4, 'cc', 32]]                           1]\n",
    "               \n",
    "    '''\n",
    "\n",
    "    X_left = []\n",
    "    X_right = []\n",
    "\n",
    "    y_left = []\n",
    "    y_right = []\n",
    "\n",
    "    X_arr = np.asarray(X, dtype=object)\n",
    "    y_arr = np.array(y)\n",
    "\n",
    "    # If split_attribute is numeric, then split on <= condition\n",
    "    if not type(split_val)==str:\n",
    "        idx_left = np.where(X_arr[:,split_attribute] <= split_val)[0]\n",
    "        idx_right = np.where(X_arr[:,split_attribute] > split_val)[0]\n",
    "        X_left = X_arr[idx_left].tolist()\n",
    "        X_right = X_arr[idx_right].tolist()\n",
    "        y_left = y_arr[idx_left].tolist()\n",
    "        y_right = y_arr[idx_right].tolist()\n",
    "\n",
    "    # If split_attribute is categorical, then split on split_val\n",
    "    else:\n",
    "        idx_left = np.where(X_arr[:,split_attribute] == split_val)[0]\n",
    "        idx_right = np.where(X_arr[:,split_attribute] != split_val)[0]   \n",
    "        X_left = X_arr[idx_left].tolist()\n",
    "        X_right = X_arr[idx_right].tolist() \n",
    "        y_left = y_arr[idx_left].tolist()\n",
    "        y_right = y_arr[idx_right].tolist()\n",
    "\n",
    "    return (X_left, X_right, y_left, y_right)\n",
    "\n",
    "\n",
    "def information_gain(previous_y, current_y):\n",
    "    # Inputs:\n",
    "    #   previous_y: the distribution of original labels (0's and 1's)\n",
    "    #   current_y:  the distribution of labels after splitting based on a particular\n",
    "    #               split attribute and split value\n",
    "\n",
    "    # TODO: Compute and return the information gain from partitioning the previous_y labels\n",
    "    # into the current_y labels.\n",
    "    # You will need to use the entropy function above to compute information gain\n",
    "    # Reference: http://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15381-s06/www/DTs.pdf\n",
    "\n",
    "    \"\"\"\n",
    "    Example:\n",
    "\n",
    "    previous_y = [0,0,0,1,1,1]\n",
    "    current_y = [[0,0], [1,1,1,0]]\n",
    "\n",
    "    info_gain = 0.45915\n",
    "    \"\"\"\n",
    "\n",
    "    info_gain = 0\n",
    "    y_left = current_y[0]\n",
    "    y_right = current_y[1]\n",
    "    info_gain = entropy(previous_y) - (entropy(y_left) * (len(y_left) / len(flatten(current_y))) + (entropy(y_right) * (len(y_right) / len(flatten(current_y)))))\n",
    "\n",
    "    return info_gain\n",
    "\n",
    "\n",
    "# WORK IN PROGRESS BELOW:\n",
    "\n",
    "# def get_split(X,y):\n",
    "#\n",
    "#     for index in range(len(X)):\n",
    "#         for row in X:\n",
    "#             groups_xleft, groups_xright, groups_yleft, groups_yright = partition_classes(X,y,index,row[index])\n",
    "#             ig = information_gain(y, [groups_yleft, groups_yright])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Majority of the code borrowed from previous work done for CSE 6242 (Data Visualization)\n",
    "Help from:\n",
    "Overall Structure: http://www.onlamp.com/pub/a/python/2006/02/09/ai_decision_trees.html?page=3\n",
    "https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/supervised_learning/decision_tree.py\n",
    "https://gist.github.com/iamaziz/02491e36490eb05a30f8\n",
    "\n",
    "https://codereview.stackexchange.com/questions/109089/id3-decision-tree-in-python\n",
    "'''\n",
    "\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self):\n",
    "        # Initializing the tree as an empty dictionary or list, as preferred\n",
    "        # self.tree = []\n",
    "        self.tree = {}\n",
    "        self.threshold = 0.1\n",
    "\n",
    "    def learn(self, X, y):\n",
    "        # TODO: Train the decision tree (self.tree) using the the sample X and labels y\n",
    "        # You will have to make use of the functions in utils.py to train the tree\n",
    "\n",
    "        # One possible way of implementing the tree:\n",
    "        #    Each node in self.tree could be in the form of a dictionary:\n",
    "        #    https://docs.python.org/2/library/stdtypes.html#mapping-types-dict\n",
    "        #    For example, a non-leaf node with two children can have a 'left' key and  a\n",
    "        #    'right' key. You can add more keys which might help in classification\n",
    "        #    (eg. split attribute and split value)\n",
    "        gain, index, value = self.try_split(X, y)\n",
    "        self.tree = self.get_split(X, y, index, value)\n",
    "        # print(self.tree)\n",
    "        self.split(self.tree, 1)\n",
    "\n",
    "    # Select the best split point for a dataset\n",
    "    '''\n",
    "    Changelog:\n",
    "    Splitting function is now (ironically) split into two functions (try_split & get_split).  \n",
    "\n",
    "        try_split: \n",
    "        Required efficiency gains by creating X_arr (numpy is much more efficient).\n",
    "        Another efficiency gain is minimizing looping.  Previously, we looped every column in X and then every\n",
    "        row in X.  Now, we only loop *once* every *unique* value in X.  \n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    def try_split(self, X, y):\n",
    "        b_index, b_value, b_gain = -1, -1, float('-inf')\n",
    "\n",
    "        X_arr = np.asarray(X, dtype=object)\n",
    "        number_of_attr = X_arr.shape[1]\n",
    "        idx = np.random.choice(range(number_of_attr), int(np.floor(0.4 * number_of_attr)), replace=False)\n",
    "        for index in idx:\n",
    "            partition_values = np.unique(X_arr[:, index], return_counts=False)\n",
    "            if not type(partition_values[0]) == str:\n",
    "                partition_values = np.percentile(partition_values, [10 * i for i in range(1, 10, 2)])\n",
    "\n",
    "            gain = np.array(\n",
    "                [information_gain(y, try_partition_classes(X, y, index, value)) for value in partition_values])\n",
    "            max_gain = max(gain)\n",
    "            if max_gain < self.threshold:\n",
    "                continue\n",
    "            else:\n",
    "                if max_gain > b_gain:\n",
    "                    b_index, b_value, b_gain = index, partition_values[np.argmax(gain)], max_gain\n",
    "\n",
    "        return (b_gain, b_index, b_value)\n",
    "\n",
    "    def get_split(self, X, y, index, value):\n",
    "        groups_xleft, groups_xright, groups_yleft, groups_yright = partition_classes(X, y, index, value)\n",
    "        return {'index': index, 'value': value, 'groups_xleft': groups_xleft, 'groups_xright': groups_xright, \\\n",
    "                'groups_yleft': groups_yleft, 'groups_yright': groups_yright}\n",
    "\n",
    "    # Create a terminal node value\n",
    "    def to_terminal(self, y):\n",
    "        return max(set(y), key=y.count)\n",
    "\n",
    "    def check_identical(self, X):\n",
    "        X_array = np.asarray(X, dtype=object)\n",
    "        for m in range(X_array.shape[1]):\n",
    "            if len(set(X_array[:, m])) > 1:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Create child splits for a node or make terminal\n",
    "    def split(self, node, depth, max_depth=5, min_size=5):\n",
    "        left_X, right_X, left_y, right_y = node['groups_xleft'], node['groups_xright'], node['groups_yleft'], node[\n",
    "            'groups_yright']\n",
    "        # del(node['groups_xleft'], node['groups_xright'], node['groups_yleft'],  node['groups_yright'])\n",
    "        # check for a no split\n",
    "        if (len(left_y) == 0 or len(right_y) == 0):\n",
    "            node['left'] = node['right'] = self.to_terminal(left_y + right_y)\n",
    "            return\n",
    "        if (len(set(left_y + right_y)) == 1):\n",
    "            node['left'] = node['right'] = self.to_terminal(left_y + right_y)\n",
    "            return\n",
    "        if (self.check_identical(left_X + right_X)):\n",
    "            node['left'] = node['right'] = self.to_terminal(left_y + right_y)\n",
    "            return\n",
    "        # check for max depth\n",
    "        if depth >= max_depth:\n",
    "            node['left'], node['right'] = self.to_terminal(left_y), self.to_terminal(right_y)\n",
    "            return\n",
    "        # process left child\n",
    "        if len(left_X) <= min_size:\n",
    "            node['left'] = self.to_terminal(left_y)\n",
    "        else:\n",
    "            gain, index, value = self.try_split(left_X, left_y)\n",
    "            if gain > self.threshold:\n",
    "                node['left'] = self.get_split(left_X, left_y, index, value)\n",
    "                self.split(node['left'], depth + 1, max_depth, min_size)\n",
    "            else:\n",
    "                node['left'] = self.to_terminal(left_y)\n",
    "        # process right child\n",
    "        if len(right_X) <= min_size:\n",
    "            node['right'] = self.to_terminal(right_y)\n",
    "        else:\n",
    "            gain, index, value = self.try_split(right_X, right_y)\n",
    "            if gain > self.threshold:\n",
    "                node['right'] = self.get_split(right_X, right_y, index, value)\n",
    "                self.split(node['right'], depth + 1, max_depth, min_size)\n",
    "            else:\n",
    "                node['right'] = self.to_terminal(right_y)\n",
    "\n",
    "    def classify(self, record):\n",
    "        # TODO: classify the record using self.tree and return the predicted label\n",
    "        node = self.tree\n",
    "        return self.predict(node, record)\n",
    "\n",
    "    def predict(self, node, record):\n",
    "        if isinstance(record[node['index']], str):\n",
    "            if record[node['index']] == node['value']:\n",
    "                if isinstance(node['left'], dict):\n",
    "                    return self.predict(node['left'], record)\n",
    "                else:\n",
    "                    return node['left']\n",
    "            else:\n",
    "                if isinstance(node['right'], dict):\n",
    "                    return self.predict(node['right'], record)\n",
    "                else:\n",
    "                    return node['right']\n",
    "        else:\n",
    "            if record[node['index']] < node['value']:\n",
    "                if isinstance(node['left'], dict):\n",
    "                    return self.predict(node['left'], record)\n",
    "                else:\n",
    "                    return node['left']\n",
    "            else:\n",
    "                if isinstance(node['right'], dict):\n",
    "                    return self.predict(node['right'], record)\n",
    "                else:\n",
    "                    return node['right']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "class RandomForest(object):\n",
    "\n",
    "    def __init__(self, num_trees):\n",
    "        # Initialization done here\n",
    "        self.num_trees = num_trees\n",
    "        self.decision_trees = [DecisionTree() for i in range(num_trees)]\n",
    "        \n",
    "    def _bootstrapping(self, XX, n):\n",
    "        # Reference: https://en.wikipedia.org/wiki/Bootstrapping_(statistics)\n",
    "        #\n",
    "        # TODO: Create a sample dataset of size n by sampling with replacement\n",
    "        #       from the original dataset XX.\n",
    "        # Note that you would also need to record the corresponding class labels\n",
    "        # for the sampled records for training purposes. \n",
    "\n",
    "        idx = np.random.choice(range(len(XX)), n, replace=True)\n",
    "        samples = [XX[id][:-1] for id in idx] # sampled dataset\n",
    "        labels = [XX[id][-1] for id in idx]  # class labels for the sampled records\n",
    "        return (samples, labels)\n",
    "\n",
    "\n",
    "    def bootstrapping(self, XX):\n",
    "        # Initializing the bootstap datasets for each tree\n",
    "        for i in range(self.num_trees):\n",
    "            data_sample, data_label = self._bootstrapping(XX, len(XX))\n",
    "            self.bootstraps_datasets.append(data_sample)\n",
    "            self.bootstraps_labels.append(data_label)\n",
    "\n",
    "\n",
    "    def fitting(self):\n",
    "        # TODO: Train `num_trees` decision trees using the bootstraps datasets\n",
    "        # and labels by calling the learn function from your DecisionTree class.\n",
    "        for i in range(self.num_trees):            \n",
    "            print \"Build the %dth tree\" % (i+1)\n",
    "            X = self.bootstraps_datasets[i]\n",
    "            y = self.bootstraps_labels[i]\n",
    "            tree =  self.decision_trees[i]\n",
    "            tree.learn(X, y)      \n",
    "\n",
    "\n",
    "    def voting(self, X):\n",
    "        y = []\n",
    "\n",
    "        for record in X:\n",
    "            # Following steps have been performed here:\n",
    "            #   1. Find the set of trees that consider the record as an \n",
    "            #      out-of-bag sample.\n",
    "            #   2. Predict the label using each of the above found trees.\n",
    "            #   3. Use majority vote to find the final label for this recod.\n",
    "            votes = []\n",
    "            for i in range(len(self.bootstraps_datasets)):\n",
    "                dataset = self.bootstraps_datasets[i]\n",
    "                if record not in dataset:\n",
    "                    OOB_tree = self.decision_trees[i]\n",
    "                    effective_vote = OOB_tree.classify(record)\n",
    "                    votes.append(effective_vote)\n",
    "\n",
    "\n",
    "            counts = np.bincount(votes)\n",
    "            \n",
    "            if len(counts) == 0:\n",
    "                # TODO: Special case \n",
    "                #  Handle the case where the record is not an out-of-bag sample\n",
    "                #  for any of the trees. \n",
    "                votes = [tree.classify(record) for tree in self.decision_trees]\n",
    "                counts = np.bincount(votes)\n",
    "                y = np.append(y, np.argmax(counts))\n",
    "            else:\n",
    "                y = np.append(y, np.argmax(counts))\n",
    "\n",
    "        return y\n",
    "\n",
    "# DO NOT change the main function apart from the forest_size parameter!\n",
    "def main():\n",
    "    X = list()\n",
    "    y = list()\n",
    "    XX = list()  # Contains data features and data labels\n",
    "    numerical_cols = set([1, 2, 7, 10, 13, 14, 15]) # indices of numeric attributes (columns)\n",
    "\n",
    "    # Loading data set\n",
    "    print 'reading data'\n",
    "    with open(\"data.csv\") as f:\n",
    "        next(f, None)\n",
    "\n",
    "        for line in csv.reader(f, delimiter=\",\"):\n",
    "            xline = []\n",
    "            for i in range(len(line)):\n",
    "                if i in numerical_cols:\n",
    "                    xline.append(ast.literal_eval(line[i]))\n",
    "                else:\n",
    "                    xline.append(line[i])\n",
    "\n",
    "            X.append(xline[:-1])\n",
    "            y.append(xline[-1])\n",
    "            XX.append(xline[:])\n",
    "\n",
    "    # TODO: Initialize according to your implementation\n",
    "    # VERY IMPORTANT: Minimum forest_size should be 10\n",
    "    forest_size = 50\n",
    "    \n",
    "    # Initializing a random forest.\n",
    "    randomForest = RandomForest(forest_size)\n",
    "\n",
    "    # Creating the bootstrapping datasets\n",
    "    print 'creating the bootstrap datasets'\n",
    "    randomForest.bootstrapping(XX)\n",
    "\n",
    "    # Building trees in the forest\n",
    "    print 'fitting the forest'\n",
    "    randomForest.fitting()\n",
    "\n",
    "    # Calculating an unbiased error estimation of the random forest\n",
    "    # based on out-of-bag (OOB) error estimate.\n",
    "    y_predicted = randomForest.voting(X)\n",
    "\n",
    "    # Comparing predicted and true labels\n",
    "    results = [prediction == truth for prediction, truth in zip(y_predicted, y)]\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = float(results.count(True)) / float(len(results))\n",
    "\n",
    "    print \"accuracy: %.4f\" % accuracy\n",
    "    print \"OOB estimate: %.4f\" % (1-accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_bootstrapping() takes exactly 3 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-50b05c21385e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bootstrapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: _bootstrapping() takes exactly 3 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "a = RandomForest(10)._bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RandomForest._bootstrapping of <__main__.RandomForest object at 0x10eccf250>>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() takes no arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c333f9e5d2af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: main() takes no arguments (1 given)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py 2.7",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
